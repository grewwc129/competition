{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import tensorflow as tf \n",
    "from keras.models import *\n",
    "from keras.layers import * \n",
    "import keras.backend as K \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_utils import *\n",
    "from scripts.nn_resnet import *\n",
    "from scripts.config import config \n",
    "from scripts.general_utils import* \n",
    "from scripts.assessment import *\n",
    "from scripts.maths import *\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fname = 'update_new_columns_trains_sets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0214 22:38:57.661866 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0214 22:38:57.696864 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0214 22:38:57.702869 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0214 22:38:57.786867 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0214 22:38:57.810904 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0214 22:39:01.064680 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0214 22:39:01.097710 16012 deprecation_wrapper.py:119] From C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = resnet(3, (400, 1))\n",
    "# model = load_model(\"C:/Users/User/Desktop/temp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x27d2008c630>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lr(model, 0.8e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "iteration: 0\n",
      "******************************\n",
      "iteration: 0, count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0214 22:39:20.328579 16012 deprecation.py:323] From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 33s 4ms/step - loss: 0.8232 - acc: 0.8822\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.6919 - acc: 0.9232\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.6162 - acc: 0.9467\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.5641 - acc: 0.9537\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.5100 - acc: 0.9657\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 2\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 19s 2ms/step - loss: 0.5149 - acc: 0.9558\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.4530 - acc: 0.9716\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.4115 - acc: 0.9801\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.3873 - acc: 0.9811\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.3650 - acc: 0.9838\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 3\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.3972 - acc: 0.9687:\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.3373 - acc: 0.9843\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.3115 - acc: 0.9880A: 1s - loss: \n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.3079 - acc: 0.9838\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.2857 - acc: 0.9879\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 4\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.3208 - acc: 0.9722\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2776 - acc: 0.9835\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2558 - acc: 0.9873\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2438 - acc: 0.9880: 1s - loss: 0.\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.2365 - acc: 0.9873\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 5\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.2709 - acc: 0.9730\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2280 - acc: 0.9868\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2213 - acc: 0.9851\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2053 - acc: 0.9908\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.2020 - acc: 0.9893\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 6\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.2349 - acc: 0.9739: 3s - lo - ETA: 1s \n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.1987 - acc: 0.9839\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.1874 - acc: 0.9871\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.1737 - acc: 0.9896\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.1685 - acc: 0.9910\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 7\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.2061 - acc: 0.9751\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.1718 - acc: 0.9860\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.1593 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.1561 - acc: 0.9889\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1543 - acc: 0.9888\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 8\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1837 - acc: 0.9803\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1545 - acc: 0.9879\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1468 - acc: 0.9879\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1379 - acc: 0.9901\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1345 - acc: 0.9894: 1s - l\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 9\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1695 - acc: 0.9799\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1384 - acc: 0.9872\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1342 - acc: 0.9869\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1253 - acc: 0.9899\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1207 - acc: 0.9911\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 10\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1440 - acc: 0.9824\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1178 - acc: 0.9912\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1091 - acc: 0.9917\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1033 - acc: 0.9929: 1s - lo\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1053 - acc: 0.9911\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 11\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1478 - acc: 0.9774\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1171 - acc: 0.9879\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.1125 - acc: 0.9877\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1053 - acc: 0.9901\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.1042 - acc: 0.9904\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 12\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.1303 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.1053 - acc: 0.9883\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0940 - acc: 0.9917 - ETA: 1s - loss: 0.\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.1005 - acc: 0.9880\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0899 - acc: 0.9922\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 13\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1283 - acc: 0.9817\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1057 - acc: 0.9858: 0s - loss: 0.1060 - acc: 0.\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0986 - acc: 0.9879\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0918 - acc: 0.9904\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0861 - acc: 0.9902: 3s - loss: 0.0831 - acc - ETA: 3s - loss: 0.0830 -\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 14\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.1165 - acc: 0.9821\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0982 - acc: 0.9886\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0859 - acc: 0.9922\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0837 - acc: 0.9911\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0798 - acc: 0.9926\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 15\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1063 - acc: 0.9843: 3s - loss: 0.107\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0882 - acc: 0.9894\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0788 - acc: 0.9907\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0748 - acc: 0.9930\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0766 - acc: 0.9910\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 16\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.1192 - acc: 0.9785\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0904 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0797 - acc: 0.9902\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0763 - acc: 0.9897: 0s - loss: 0.0763 - acc: \n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0776 - acc: 0.9908\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 17\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0983 - acc: 0.9847: 1s - loss:\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0761 - acc: 0.9908\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0730 - acc: 0.9908\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0712 - acc: 0.9916\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0703 - acc: 0.9928ETA: 2s - - ETA: 0s - loss: 0.0705 - acc: 0\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 18\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0858 - acc: 0.9855\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0666 - acc: 0.9927: 0s - loss: 0.0666 - acc: 0.992\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0682 - acc: 0.9926\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0607 - acc: 0.9946\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0609 - acc: 0.9939: 4s -\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 19\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0914 - acc: 0.9845\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0693 - acc: 0.9906\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0663 - acc: 0.9917\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0608 - acc: 0.9933\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0621 - acc: 0.9929\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 20\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0820 - acc: 0.9864:\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0670 - acc: 0.9902\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0556 - acc: 0.9948\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0520 - acc: 0.9960\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0555 - acc: 0.9930\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 21\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0879 - acc: 0.9833\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0706 - acc: 0.9896\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0622 - acc: 0.9918\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0557 - acc: 0.9934\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0541 - acc: 0.9939\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 22\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0871 - acc: 0.9833\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0712 - acc: 0.9884\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0625 - acc: 0.9910\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0495 - acc: 0.9958\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0528 - acc: 0.9935: 1s - los\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 23\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0852 - acc: 0.9838\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0649 - acc: 0.9902: 0s - loss: 0.0650 - acc: \n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0628 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0512 - acc: 0.9956\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0496 - acc: 0.9946\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 24\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0912 - acc: 0.9811\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0629 - acc: 0.9915\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0596 - acc: 0.9916\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0533 - acc: 0.9937\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0507 - acc: 0.9940\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 25\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0819 - acc: 0.9838\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0583 - acc: 0.9918\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0486 - acc: 0.9940\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0535 - acc: 0.9934\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0414 - acc: 0.9966\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 26\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0912 - acc: 0.9816\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0656 - acc: 0.9894\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0549 - acc: 0.9929\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0545 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0471 - acc: 0.9950\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 27\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0838 - acc: 0.9830\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0624 - acc: 0.9901\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0515 - acc: 0.9939\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0439 - acc: 0.9962\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0522 - acc: 0.9932\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 28\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0780 - acc: 0.9882\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0588 - acc: 0.9916\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0502 - acc: 0.9943\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0470 - acc: 0.9944\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0458 - acc: 0.9940\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 29\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0801 - acc: 0.9833\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0524 - acc: 0.9918: 1s \n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0452 - acc: 0.9950\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0450 - acc: 0.9943\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0420 - acc: 0.9957\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 30\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0797 - acc: 0.9833\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0540 - acc: 0.9918\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0432 - acc: 0.9954\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0477 - acc: 0.9937\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0425 - acc: 0.9958\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 31\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0725 - acc: 0.9857\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0538 - acc: 0.9910\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0444 - acc: 0.9940\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0382 - acc: 0.9965\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0443 - acc: 0.9937\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 32\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0768 - acc: 0.9852\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0530 - acc: 0.9907\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0464 - acc: 0.9938\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0401 - acc: 0.9951: 4s - l\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0452 - acc: 0.9941\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 33\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0747 - acc: 0.9843\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0496 - acc: 0.9922\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0416 - acc: 0.9957\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0466 - acc: 0.9922\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0438 - acc: 0.9943\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 34\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0662 - acc: 0.9862\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0476 - acc: 0.9926\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0400 - acc: 0.9954\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0373 - acc: 0.9957: 0s - loss: 0.0374 - acc: 0\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0383 - acc: 0.9951\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 35\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0751 - acc: 0.9821\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0553 - acc: 0.9894\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0459 - acc: 0.9930\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0429 - acc: 0.9948\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0413 - acc: 0.9938\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 36\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0667 - acc: 0.9863\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0494 - acc: 0.9908\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0382 - acc: 0.9957\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0392 - acc: 0.9952\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0377 - acc: 0.9951: 2s - loss: 0.0382 -  - ETA: 1s\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 37\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0664 - acc: 0.9869\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0477 - acc: 0.9924\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0399 - acc: 0.9948\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0351 - acc: 0.9956\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0402 - acc: 0.9948\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 38\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0723 - acc: 0.9858\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0499 - acc: 0.9926\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0490 - acc: 0.9928\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0384 - acc: 0.9961\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0374 - acc: 0.9956\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 39\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0628 - acc: 0.9863\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0454 - acc: 0.9924\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0368 - acc: 0.9949: 3s - loss: 0.03 - ETA: 2s - loss: 0.0370 - acc - ETA: 2s - loss: 0.0368 - ac - ETA: 1s - loss: 0.03 - ETA: 0s - loss: 0.0370 - acc: \n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0331 - acc: 0.9958\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0367 - acc: 0.9937\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 40\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0695 - acc: 0.9839\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0465 - acc: 0.9927\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0385 - acc: 0.9949\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0377 - acc: 0.9945\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0367 - acc: 0.9949\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 41\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0650 - acc: 0.9866\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0465 - acc: 0.9912\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0384 - acc: 0.9954\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0346 - acc: 0.9960\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0385 - acc: 0.9939\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 42\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0705 - acc: 0.9836\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0516 - acc: 0.9906\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0429 - acc: 0.9929\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0344 - acc: 0.9962\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0374 - acc: 0.9945\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 43\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0539 - acc: 0.9893\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0421 - acc: 0.9935\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0335 - acc: 0.9952\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0310 - acc: 0.9969\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0321 - acc: 0.9960\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 44\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0691 - acc: 0.9845\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0446 - acc: 0.9929: 1s - loss: 0.\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0390 - acc: 0.9943A: 0s - loss: 0.0386 - acc: 0\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0387 - acc: 0.9946\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0332 - acc: 0.9960: 1s - loss: 0\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 45\n",
      "Epoch 1/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0760 - acc: 0.9823\n",
      "Epoch 2/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0525 - acc: 0.9888\n",
      "Epoch 3/5\n",
      "8192/8192 [==============================] - 17s 2ms/step - loss: 0.0467 - acc: 0.9912\n",
      "Epoch 4/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0384 - acc: 0.9951\n",
      "Epoch 5/5\n",
      "8192/8192 [==============================] - 18s 2ms/step - loss: 0.0345 - acc: 0.9957\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 46\n",
      "Epoch 1/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0751 - acc: 0.9829\n",
      "Epoch 2/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0514 - acc: 0.9917: 1s - loss: 0.0\n",
      "Epoch 3/5\n",
      "8191/8191 [==============================] - 17s 2ms/step - loss: 0.0412 - acc: 0.9932\n",
      "Epoch 4/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0367 - acc: 0.9949\n",
      "Epoch 5/5\n",
      "8191/8191 [==============================] - 18s 2ms/step - loss: 0.0362 - acc: 0.9945\n",
      "******************************\n",
      "******************************\n",
      "iteration: 0, count: 47\n",
      "Epoch 1/5\n",
      "2400/8191 [=======>......................] - ETA: 12s - loss: 0.0634 - acc: 0.9858"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "\n",
    "    batch_size = 1024 * 8\n",
    "    for i in range(1):\n",
    "        if i > 0:\n",
    "            decay_lr(model)\n",
    "        if i == 5:\n",
    "            model.save(\"C:/Users/User/Desktop/resNet_temp.h5\", overwrite=True)\n",
    "        print(\"#\"*30)\n",
    "        print('iteration: {}'.format(i))\n",
    "        df = pd.read_csv(fname, iterator=True, low_memory=False)\n",
    "        count = 0\n",
    "        while 1:\n",
    "            try:\n",
    "                cur = df.get_chunk(batch_size)\n",
    "                train_x, train_y = trim_df(cur)\n",
    "                print(\"*\" * 30)\n",
    "                print(\"iteration: {}, count: {}\".format(i, count + 1))\n",
    "                count += 1\n",
    "                model.fit(train_x, train_y, epochs=5)\n",
    "                print(\"*\" * 30)\n",
    "            except StopIteration:\n",
    "                break  \n",
    "                \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('C:/Users/User/Desktop/temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2592</th>\n",
       "      <th>2593</th>\n",
       "      <th>2594</th>\n",
       "      <th>2595</th>\n",
       "      <th>2596</th>\n",
       "      <th>2597</th>\n",
       "      <th>2598</th>\n",
       "      <th>2599</th>\n",
       "      <th>2600</th>\n",
       "      <th>2601</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.167630</td>\n",
       "      <td>128.404863</td>\n",
       "      <td>113.342102</td>\n",
       "      <td>96.332659</td>\n",
       "      <td>155.429838</td>\n",
       "      <td>103.355702</td>\n",
       "      <td>137.708264</td>\n",
       "      <td>37.861562</td>\n",
       "      <td>39.673803</td>\n",
       "      <td>50.543431</td>\n",
       "      <td>...</td>\n",
       "      <td>155.748438</td>\n",
       "      <td>164.905856</td>\n",
       "      <td>152.331062</td>\n",
       "      <td>141.852236</td>\n",
       "      <td>135.080094</td>\n",
       "      <td>133.500859</td>\n",
       "      <td>154.136530</td>\n",
       "      <td>171.568474</td>\n",
       "      <td>star</td>\n",
       "      <td>7dad7234f998192fdbd8183952ef20c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-346.646602</td>\n",
       "      <td>-171.032817</td>\n",
       "      <td>186.992031</td>\n",
       "      <td>-716.384903</td>\n",
       "      <td>254.621417</td>\n",
       "      <td>732.285840</td>\n",
       "      <td>92.950140</td>\n",
       "      <td>871.351690</td>\n",
       "      <td>-55.170295</td>\n",
       "      <td>-184.566823</td>\n",
       "      <td>...</td>\n",
       "      <td>483.402540</td>\n",
       "      <td>521.284520</td>\n",
       "      <td>542.210809</td>\n",
       "      <td>488.168831</td>\n",
       "      <td>495.515646</td>\n",
       "      <td>519.919761</td>\n",
       "      <td>528.461916</td>\n",
       "      <td>509.382020</td>\n",
       "      <td>star</td>\n",
       "      <td>e7813ce88966dd145ca4a604eb66ad96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2387.394914</td>\n",
       "      <td>2962.318974</td>\n",
       "      <td>3514.910243</td>\n",
       "      <td>3643.305956</td>\n",
       "      <td>3423.303276</td>\n",
       "      <td>3647.917856</td>\n",
       "      <td>3908.737325</td>\n",
       "      <td>3387.910634</td>\n",
       "      <td>2762.518797</td>\n",
       "      <td>2953.116359</td>\n",
       "      <td>...</td>\n",
       "      <td>5165.653546</td>\n",
       "      <td>5118.992689</td>\n",
       "      <td>4951.877510</td>\n",
       "      <td>4634.349520</td>\n",
       "      <td>4406.328902</td>\n",
       "      <td>4472.693075</td>\n",
       "      <td>4795.940878</td>\n",
       "      <td>5121.840348</td>\n",
       "      <td>star</td>\n",
       "      <td>045175f20fb74d88354cd3aa56620542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.562754</td>\n",
       "      <td>59.513893</td>\n",
       "      <td>69.655255</td>\n",
       "      <td>71.265120</td>\n",
       "      <td>141.805016</td>\n",
       "      <td>48.109098</td>\n",
       "      <td>139.253948</td>\n",
       "      <td>68.265771</td>\n",
       "      <td>90.808146</td>\n",
       "      <td>112.768287</td>\n",
       "      <td>...</td>\n",
       "      <td>48.698369</td>\n",
       "      <td>46.498682</td>\n",
       "      <td>46.400705</td>\n",
       "      <td>43.561856</td>\n",
       "      <td>27.760035</td>\n",
       "      <td>18.326394</td>\n",
       "      <td>25.614916</td>\n",
       "      <td>33.622985</td>\n",
       "      <td>star</td>\n",
       "      <td>2c9879d370ef4d080fde817d87bc2c30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.760337</td>\n",
       "      <td>20.949811</td>\n",
       "      <td>57.370654</td>\n",
       "      <td>95.891313</td>\n",
       "      <td>104.290857</td>\n",
       "      <td>143.640962</td>\n",
       "      <td>69.819133</td>\n",
       "      <td>78.375157</td>\n",
       "      <td>80.904606</td>\n",
       "      <td>144.822199</td>\n",
       "      <td>...</td>\n",
       "      <td>55.154461</td>\n",
       "      <td>53.332641</td>\n",
       "      <td>49.130921</td>\n",
       "      <td>45.127950</td>\n",
       "      <td>40.212215</td>\n",
       "      <td>42.787378</td>\n",
       "      <td>49.548343</td>\n",
       "      <td>56.441171</td>\n",
       "      <td>star</td>\n",
       "      <td>a1bc6a343ad39d7a8c75a2ae59771eb1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0            1            2            3            4     \\\n",
       "0    41.167630   128.404863   113.342102    96.332659   155.429838   \n",
       "1  -346.646602  -171.032817   186.992031  -716.384903   254.621417   \n",
       "2  2387.394914  2962.318974  3514.910243  3643.305956  3423.303276   \n",
       "3    80.562754    59.513893    69.655255    71.265120   141.805016   \n",
       "4   117.760337    20.949811    57.370654    95.891313   104.290857   \n",
       "\n",
       "          5            6            7            8            9     ...  \\\n",
       "0   103.355702   137.708264    37.861562    39.673803    50.543431  ...   \n",
       "1   732.285840    92.950140   871.351690   -55.170295  -184.566823  ...   \n",
       "2  3647.917856  3908.737325  3387.910634  2762.518797  2953.116359  ...   \n",
       "3    48.109098   139.253948    68.265771    90.808146   112.768287  ...   \n",
       "4   143.640962    69.819133    78.375157    80.904606   144.822199  ...   \n",
       "\n",
       "          2592         2593         2594         2595         2596  \\\n",
       "0   155.748438   164.905856   152.331062   141.852236   135.080094   \n",
       "1   483.402540   521.284520   542.210809   488.168831   495.515646   \n",
       "2  5165.653546  5118.992689  4951.877510  4634.349520  4406.328902   \n",
       "3    48.698369    46.498682    46.400705    43.561856    27.760035   \n",
       "4    55.154461    53.332641    49.130921    45.127950    40.212215   \n",
       "\n",
       "          2597         2598         2599  2600  \\\n",
       "0   133.500859   154.136530   171.568474  star   \n",
       "1   519.919761   528.461916   509.382020  star   \n",
       "2  4472.693075  4795.940878  5121.840348  star   \n",
       "3    18.326394    25.614916    33.622985  star   \n",
       "4    42.787378    49.548343    56.441171  star   \n",
       "\n",
       "                               2601  \n",
       "0  7dad7234f998192fdbd8183952ef20c8  \n",
       "1  e7813ce88966dd145ca4a604eb66ad96  \n",
       "2  045175f20fb74d88354cd3aa56620542  \n",
       "3  2c9879d370ef4d080fde817d87bc2c30  \n",
       "4  a1bc6a343ad39d7a8c75a2ae59771eb1  \n",
       "\n",
       "[5 rows x 2602 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0214 19:27:09.203066 16168 deprecation.py:323] From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"C:/Users/User/Desktop/resNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_name = \"C:/Users/User/Desktop/go_download/val_sets_v1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(val_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_name = \"C:/Users/User/Desktop/go_download/val_labels_v1.csv\"\n",
    "val_df_y = pd.read_csv(val_y_name)\n",
    "val_df_x = val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = val_df_x\n",
    "vy = val_df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = vx.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vy = vy['label'].values\n",
    "vy = encode_names(vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vx = np.array([average_bin(np.arange(2600), vxi, num_bins=300) for vxi in vx])\n",
    "\n",
    "vx = vx[:, 100:-50]\n",
    "\n",
    "vx = average_bin_faster(vx, 400)\n",
    "vx = vx.reshape(*vx.shape, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pred = model.predict(vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927658636897767"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precision(vy, v_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723642776690872"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(vy, v_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/User/Desktop/resNet.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pred_cls = np.argmax(v_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_y['pred_cls'] = v_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190624"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_to_name(cls):\n",
    "    if cls == 0:\n",
    "        return 'star'\n",
    "    if cls == 1:\n",
    "        return 'galaxy'\n",
    "    return 'qso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_y['pred_cls'] = val_df_y['pred_cls'].apply(cls_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df_y[val_df_y['label']!=val_df_y['pred_cls']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1379, 189245)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = val_df_y[val_df_y['pred_cls'] != val_df_y['label']]\n",
    "same = val_df_y[val_df_y['pred_cls'] == val_df_y['label']]\n",
    "len(diff), len(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['pred'] = val_df_y['pred_cls']\n",
    "val_df['label'] = val_df_y['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_spectrum = val_df.loc[val_df['id'].isin(diff['id'])]\n",
    "same_spectrum = val_df.loc[val_df['id'].isin(same['id'])]\n",
    "\n",
    "diff_spectrum = diff_spectrum.drop('id', axis=1)\n",
    "same_spectrum = same_spectrum.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1379, 189245)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_spectrum), len(same_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_spectrum_star = same_spectrum[same_spectrum['label']=='star']\n",
    "same_spectrum_gal = same_spectrum[same_spectrum['label']=='galaxy']\n",
    "same_spectrum_qso = same_spectrum[same_spectrum['label']=='qso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([same_spectrum_star.iloc[:100,:], same_spectrum_gal.iloc[:100,:], \n",
    "                 same_spectrum_qso.iloc[:100,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_spectrum.to_csv(\"C:/Users/User/Desktop/temp/predict_wrong_spectral.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"C:/Users/User/Desktop/temp/predict_right_spectral.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FE0</th>\n",
       "      <th>FE1</th>\n",
       "      <th>FE2</th>\n",
       "      <th>FE3</th>\n",
       "      <th>FE4</th>\n",
       "      <th>FE5</th>\n",
       "      <th>FE6</th>\n",
       "      <th>FE7</th>\n",
       "      <th>FE8</th>\n",
       "      <th>FE9</th>\n",
       "      <th>...</th>\n",
       "      <th>FE2592</th>\n",
       "      <th>FE2593</th>\n",
       "      <th>FE2594</th>\n",
       "      <th>FE2595</th>\n",
       "      <th>FE2596</th>\n",
       "      <th>FE2597</th>\n",
       "      <th>FE2598</th>\n",
       "      <th>FE2599</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>20.539032</td>\n",
       "      <td>-11.496449</td>\n",
       "      <td>20.704480</td>\n",
       "      <td>10.320412</td>\n",
       "      <td>24.132203</td>\n",
       "      <td>-5.339583</td>\n",
       "      <td>18.627630</td>\n",
       "      <td>3.959894</td>\n",
       "      <td>64.945979</td>\n",
       "      <td>9.173379</td>\n",
       "      <td>...</td>\n",
       "      <td>37.511490</td>\n",
       "      <td>34.740448</td>\n",
       "      <td>39.744783</td>\n",
       "      <td>43.466447</td>\n",
       "      <td>36.557037</td>\n",
       "      <td>29.749146</td>\n",
       "      <td>29.873103</td>\n",
       "      <td>28.686555</td>\n",
       "      <td>star</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>4.080163</td>\n",
       "      <td>5.964849</td>\n",
       "      <td>11.200888</td>\n",
       "      <td>-9.123729</td>\n",
       "      <td>-16.047049</td>\n",
       "      <td>-2.116285</td>\n",
       "      <td>11.063445</td>\n",
       "      <td>0.660645</td>\n",
       "      <td>10.570564</td>\n",
       "      <td>16.589804</td>\n",
       "      <td>...</td>\n",
       "      <td>5.467748</td>\n",
       "      <td>6.397606</td>\n",
       "      <td>6.230656</td>\n",
       "      <td>6.257501</td>\n",
       "      <td>5.404189</td>\n",
       "      <td>4.980243</td>\n",
       "      <td>5.226400</td>\n",
       "      <td>5.350140</td>\n",
       "      <td>star</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>-279.087973</td>\n",
       "      <td>-47.678342</td>\n",
       "      <td>-5.105812</td>\n",
       "      <td>198.935923</td>\n",
       "      <td>-151.138377</td>\n",
       "      <td>-36.066876</td>\n",
       "      <td>109.816511</td>\n",
       "      <td>69.809897</td>\n",
       "      <td>91.818532</td>\n",
       "      <td>-236.827852</td>\n",
       "      <td>...</td>\n",
       "      <td>174.588257</td>\n",
       "      <td>120.880636</td>\n",
       "      <td>87.382189</td>\n",
       "      <td>167.457078</td>\n",
       "      <td>185.419524</td>\n",
       "      <td>139.296300</td>\n",
       "      <td>121.636615</td>\n",
       "      <td>100.354468</td>\n",
       "      <td>star</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2.146430</td>\n",
       "      <td>2.414457</td>\n",
       "      <td>3.285812</td>\n",
       "      <td>0.763399</td>\n",
       "      <td>1.679500</td>\n",
       "      <td>2.431333</td>\n",
       "      <td>-0.577207</td>\n",
       "      <td>2.332459</td>\n",
       "      <td>0.348145</td>\n",
       "      <td>2.006564</td>\n",
       "      <td>...</td>\n",
       "      <td>9.447075</td>\n",
       "      <td>9.702508</td>\n",
       "      <td>9.957942</td>\n",
       "      <td>10.213376</td>\n",
       "      <td>10.468810</td>\n",
       "      <td>10.724243</td>\n",
       "      <td>10.979677</td>\n",
       "      <td>11.235111</td>\n",
       "      <td>qso</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>72.963981</td>\n",
       "      <td>51.649080</td>\n",
       "      <td>56.697270</td>\n",
       "      <td>74.403605</td>\n",
       "      <td>48.042003</td>\n",
       "      <td>87.167193</td>\n",
       "      <td>85.622775</td>\n",
       "      <td>0.637782</td>\n",
       "      <td>106.732244</td>\n",
       "      <td>-21.642268</td>\n",
       "      <td>...</td>\n",
       "      <td>59.193337</td>\n",
       "      <td>55.195674</td>\n",
       "      <td>52.769990</td>\n",
       "      <td>53.114714</td>\n",
       "      <td>53.977462</td>\n",
       "      <td>54.031909</td>\n",
       "      <td>53.538296</td>\n",
       "      <td>56.745403</td>\n",
       "      <td>star</td>\n",
       "      <td>galaxy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FE0        FE1        FE2         FE3         FE4        FE5  \\\n",
       "399   20.539032 -11.496449  20.704480   10.320412   24.132203  -5.339583   \n",
       "515    4.080163   5.964849  11.200888   -9.123729  -16.047049  -2.116285   \n",
       "585 -279.087973 -47.678342  -5.105812  198.935923 -151.138377 -36.066876   \n",
       "743    2.146430   2.414457   3.285812    0.763399    1.679500   2.431333   \n",
       "824   72.963981  51.649080  56.697270   74.403605   48.042003  87.167193   \n",
       "\n",
       "            FE6        FE7         FE8         FE9  ...      FE2592  \\\n",
       "399   18.627630   3.959894   64.945979    9.173379  ...   37.511490   \n",
       "515   11.063445   0.660645   10.570564   16.589804  ...    5.467748   \n",
       "585  109.816511  69.809897   91.818532 -236.827852  ...  174.588257   \n",
       "743   -0.577207   2.332459    0.348145    2.006564  ...    9.447075   \n",
       "824   85.622775   0.637782  106.732244  -21.642268  ...   59.193337   \n",
       "\n",
       "         FE2593     FE2594      FE2595      FE2596      FE2597      FE2598  \\\n",
       "399   34.740448  39.744783   43.466447   36.557037   29.749146   29.873103   \n",
       "515    6.397606   6.230656    6.257501    5.404189    4.980243    5.226400   \n",
       "585  120.880636  87.382189  167.457078  185.419524  139.296300  121.636615   \n",
       "743    9.702508   9.957942   10.213376   10.468810   10.724243   10.979677   \n",
       "824   55.195674  52.769990   53.114714   53.977462   54.031909   53.538296   \n",
       "\n",
       "         FE2599  pred   label  \n",
       "399   28.686555  star  galaxy  \n",
       "515    5.350140  star  galaxy  \n",
       "585  100.354468  star  galaxy  \n",
       "743   11.235111   qso  galaxy  \n",
       "824   56.745403  star  galaxy  \n",
       "\n",
       "[5 rows x 2602 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_spectrum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_y['label'] = val_df_y['pred_cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_y = val_df_y[['id','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190624"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_y.to_csv(\"C:/Users/User/Desktop/go_download/submit_3 .csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
